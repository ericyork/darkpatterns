<h2>Introduction</h2>
<p><span class="dropcap t">T</span>he concept of dark patterns entered mainstream discourse somewhere in 2016 (after kicking around for several years in user experience design and web development circles), with a host of articles in technology-oriented publications like <em>Recode</em>, <em>Smashing</em>, <em>Ars Technica</em>, <em>Techcrunch</em>, <em>The Verge</em>, <em>Gizmodo</em>, and <em>A List Apart</em>, as well as in more traditional news outlets such as <em>The New York Times</em> and <em>Reuters</em>. The events of 2016 had pushed the topic to prominence as it became ever more clear that agents of the Russian government, in cooperation with technology corporations small and large, had interfered in the U.S. Presidential Election and had done so, according to journalists, at least in part using the tools provided by dark patterns. In “The Year Dark Patterns Won” journalist Kelsey Campbell-Dollaghan (2016) writes that, during the election, “dark patterns . . . [were] wielded as weapons against democracy” (p.??), and she identifies several ways voters were exploited both by members and allies of the Trump campaign and by social media platforms like Facebook and Twitter, ranging from entirely fabricated news stories to confirmation bias in browsing algorithm. Campell-Dollaghan writes that “Even the details of interface used by both Facebook and Google mislead users: By cloaking every URL in the same ‘pretty’ interface elements, whether from ABCNews.com or its fake news counterpart ABCNews.co.co, both companies lent legitimacy to lies through design” (p.??). All this journalism eventually contributed to the introduction of a bipartisan bill in 2019 (not passed at the time of this writing). The DETOUR Act would “ban large social networking platforms from using ‘dark patterns’ to trick users into giving their consent for data collection operations” (ZDNet cite ???), as well as order these platforms to work with the FTC to create a professional standards body that would develop and promulgate best practices in interface design. Whether or not this bill or another like it passes into law, there’s not a little irony in the idea that employees of Facebook and Google should be the one to determine what web interfaces should look like.</p>
<p>Meanwhile, during this time, studies on dark patterns began to proliferate in journals dedicated to, variously, the design of interactive systems, to video game development, and to human-computer interaction, among others. These studies and others like them voice concerns that dark patterns compromise users’ privacy (Bocsh et al., 2016), negatively impact users’ finances (Zagal, Bjork and Lewis, 2013), and their attention and levels of engagement (Greenberg et al., 2014). In addition, several of these studies point to the spread of dark patterns as indicative of the need for more widespread and sustained discussions of ethics in interaction design, (Gray et al., 2018) and user experience design (Fansher, Sai Chivukula, and Gray, 2018) to educate designers and curb the use of deceptive patterns. From a rhetorical perspective, Michael Trice and Liza Potts (2018) study the infamous GamerGate hoax and find extensive use of dark patterns in social media platform design used to artificially amplify alt-right rhetoric (p.3), showing how dark patterns can, in this fashion, influence identities, cultures and politics.</p>
<p>However, all of these studies rely to a greater or lesser extent on the definition of dark patterns established by user experience researcher Harry Brignull (who originally coined the term in 2010 after a real-life mugging resulted in the insight that many of the interactions he was seeing online were much the same): that is, a dark pattern is “a user interface carefully crafted to trick users into doing things they might not otherwise do” (Brignull, 2013, p.1), but using this definition has the unfortunate effect of conflating the deceptive interfaces with the design patterns used to create them. Second, all of these studies use the same categorization scheme Brignull developed and pressed into rough service online in 2010, and this taxonomy is more suited to social media shareability than to precise academic discussion. Its categories overlap in confusing ways and it includes heavily loaded phrases such as “roach motel” and “bait and switch”, which impair discussion. Third, all of these studies either explicitly or implicitly accept the connotation of morality conveyed by the ‘dark’ part of the pattern's moniker, and call them at times “unethical” (p.??), “manipulative” (p.??) and even “evil” (Gray et al., 2018, p.4). All too often, this leads researchers to see dark patterns only antagonistically. From this perspective, dark patterns are a set of techniques that designers must eschew and users must learn to identify and avoid. So, the term ‘dark pattern’ comes to us already freighted with problems: an inadequate definition, an idiosyncratic taxonomy, and a predetermined moral valence, and we must address these structural infirmities before we can move on to more important questions about the role dark patterns should play in our discourse and the mechanism by which they actually function.</p>
<p>	In the discourse of rhetoric and composition, interfaces as such have been studied rigorously since computers first started appearing in workplaces and classrooms during the 80s and 90s. After all, interfaces are by their nature persuasive, multimodal, context-dependent, and audience-oriented—in other words, profoundly rhetorical. Beginning notably with Cynthia Selfe and Richard Selfe’s (1994) idea of the interface as “a linguistic contact zone” that supports “a larger cultural system of differential power” (p.65), interfaces have been critically theorized in a variety of ways: in email (Moran, 1995, p.??), in data displays (Kostelnick, 2008 p.117), in the usability of information systems (Spinuzzi, 2001, p.43), in the networked spaces of the ‘datacloud’ (Johnson-Eilola, 2004, p.26 ), in design practice (Wysocki and Jasken, 2004, p.30), in interfaces as texts (Warnick (2005, p.328), and in social media interfaces (Arola, 2010, p.7), as well others too numerous to continue to summarize. One of the most significant ideas to come out of this body of scholarship is the importance of forming balanced conceptions of technologies and their use, one that is both optimistic and critical. “Interfaces are thoroughly rhetorical” Wysocki and Jasken (2004) write, they “are about the relations we construct with each other—how we perceive and try to shape each other—through the artifacts we make for each other” (p.33). Dark patterns and the deceptive interfaces they inform deserve no less a balanced treatment: they are rhetorical (albeit for definitions of rhetoric we may wish to exclude) and they are about the relations we construct between each other (albeit relationships that are decidedly unhealthy).</p>
<p>	The moment one succumbs to a deceptive interface is highly instructive: it constitutes the edge case when human interpretation spectacularly fails, when perceptual lacunae of which we’re typically unaware suddenly become our Achilles Heel, threatening our very subjecthood. It is the reverse of communication, a deliberate miscommunication that exploits a kind of blind spot in the user’s mind. This moment of surprise is often followed by an unpleasant feeling, as what had at first seemed innocent is instead revealed as sinister. Consider the deceptive interface depicted in Figure ##. A human hair has been meticulously photoshopped to appear to sit on the user’s screen, prompting them to wipe it off and in so doing, to activate the link wrapped around the entire image. Any user, trained rhetorician and practicing UX designer and developer or not, could try to wipe the hair away and trigger whatever malware package it links to. An innocent hair, a malicious trigger. A moment of surprise as you realize the elaborately constructed sneaker ad consisting of layers of visual and textual communication is actually just a ruse built to deliver the hair. Now that unpleasant, sinking feeling. I’ve been duped. A moment like this can prompt anyone, but especially a rhetorician and designer like myself, to wonder what’s actually going on in these deceptive interfaces. What are dark patterns really and, more importantly, how do they work, exactly? How can we distinguish among them or distinguish them from the “light patterns” they mimic? Finally, what do these extreme communicative cases have to teach us about rhetoric? About design?</p>

<figure>
	<img src="" alt="" >
	<figcaption>Figure ##: Fake Hair. Posted to Twitter (https://twiter.com/???) by user @????, this deceptive interface consists of a fake hair photoshopped onto a sneaker advertisement so it looks like it sits atop the screen. When the user tries to wipe it away, it triggers the link wrapped around the whole image.</figcaption>
</figure>

<p>	In the sections that follow, I redefine dark patterns and the deceptive interfaces they generate by putting them into the context of their closest relatives: acts of online deception and misleading data visualizations (deceptive graphs and charts). By situating dark patterns and deceptive interfaces in this context, it provides us with the theoretical framework necessary to analyze deceptive interfaces: using both primarily rhetorical theories of deception and primarily visual theories of perception—and this allows us to rediscover the relationship between these estranged twins—deception and perception are but different facets of the same art, techne pantoi, as the ancients called it, and there in the details of the techne we find the mechanism, similar in kind to the pulley or the lever, evident in both ancient and modern texts, a mechanical advantage in communication, that seizes opportunity on the wing and effects a stunning reversal. Using this dual theory, I conduct a reading of representative examples of deceptive interfaces composed according to dark patterns to illustrate how supports analysis of a variety of deceptive texts. For dark patterns rely on a combination of both rhetorical cunning—to recognize and exploit opportune moments and create the sense of befuddlement the ancients called aporia—as well as on certain kinds of optical illusions that deceive the eye and the hand, and, in so doing, the mind.</p>
